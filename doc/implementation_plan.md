# Plano de Implementa√ß√£o: Subsistema de Mem√≥ria Moderno para Forge

## üìã Vis√£o Geral

Este documento descreve a arquitetura e implementa√ß√£o de um subsistema de mem√≥ria **moderno, robusto e profissional** para o Kernel Forge, seguindo os princ√≠pios de design mais avan√ßados da ind√∫stria, indo al√©m do modelo cl√°ssico do Linux.

---

## üéØ Princ√≠pios Fundamentais

| Princ√≠pio | Descri√ß√£o |
|-----------|-----------|
| **Isolamento Absoluto** | Cada processo nasce com address space vazio. Nada herdado por acidente. |
| **Lazy Everything** | P√°gina s√≥ existe quando algu√©m toca. Page fault √© caminho normal. |
| **Ownership Expl√≠cito** | Cada frame f√≠sico tem dono(s). Refcount sempre. Sem dono ‚Üí livre. |
| **Separa√ß√£o Clara** | Virtual ‚â† f√≠sico. Kernel ‚â† user. Dado ‚â† permiss√£o. |
| **Metadados Ricos** | Cada regi√£o tem inten√ß√£o (heap, stack, framebuffer). Kernel decide baseado nisso. |
| **Zero Compartilhamento Impl√≠cito** | Compartilhar mem√≥ria √© sempre expl√≠cito via syscall. |

---

## üèóÔ∏è Arquitetura Proposta

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           KERNEL MEMORY SUBSYSTEM                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ                         KERNEL HEAP (HHDM)                          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Buddy + Slab ‚Üí Box, Vec, Arc para estruturas internas do kernel    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                    ‚Üë                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ                    ADDRESS SPACE MANAGER                            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  AddressSpace (CR3) + VMA List + Page Fault Handler                 ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                    ‚Üë                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ                    PAGE FRAME MANAGER (PFM)                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Frame ‚Üí Owner ‚Üí RefCount ‚Üí State (Free/Used/COW/Pinned)            ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                    ‚Üë                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ                    PHYSICAL MEMORY MANAGER (PMM)                    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Bitmap ‚Üí PhysFrame ‚Üí Boot-time allocation                          ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìê Layout de Mem√≥ria Virtual (x86_64)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           USERSPACE (0-128TB)          ‚îÇ        KERNEL (128TB+)           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 0x0000_0000_0000_0000                  ‚îÇ 0xFFFF_8000_0000_0000            ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ [N√ÉO MAPEADO - Guard Page]         ‚îÇ ‚îî‚îÄ‚îÄ HHDM (Direct Map RAM)        ‚îÇ
‚îÇ                                        ‚îÇ     Toda RAM f√≠sica mapeada      ‚îÇ
‚îÇ 0x0000_0000_0040_0000 (4MB+)           ‚îÇ     phys_to_virt(p) = HHDM + p   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ ELF Code/Data                      ‚îÇ                                  ‚îÇ
‚îÇ     (Mapeado sob demanda por VMA)      ‚îÇ 0xFFFF_9000_0000_0000            ‚îÇ
‚îÇ                                        ‚îÇ ‚îî‚îÄ‚îÄ Kernel Heap                  ‚îÇ
‚îÇ 0x0000_0001_0000_0000 (4GB+)           ‚îÇ     (Buddy + Slab)               ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ Heap (brk() / mmap an√¥nimo)        ‚îÇ                                  ‚îÇ
‚îÇ     Base din√¢mica (ASLR)               ‚îÇ 0xFFFF_9100_0000_0000            ‚îÇ
‚îÇ     Cresce via VMA expandido           ‚îÇ ‚îî‚îÄ‚îÄ Kernel Stacks (per-task)     ‚îÇ
‚îÇ                                        ‚îÇ                                  ‚îÇ
‚îÇ 0x0000_7000_0000_0000 (112TB+)         ‚îÇ 0xFFFF_FE00_0000_0000            ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ mmap() region                      ‚îÇ ‚îî‚îÄ‚îÄ Scratch Page (temp mapping)  ‚îÇ
‚îÇ     Shared memory, files, etc.         ‚îÇ                                  ‚îÇ
‚îÇ                                        ‚îÇ 0xFFFF_FFFF_8000_0000            ‚îÇ
‚îÇ 0x0000_7FFF_FFFF_F000                  ‚îÇ ‚îî‚îÄ‚îÄ Kernel Text/Data (-2GB)      ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ Stack (cresce para baixo)          ‚îÇ     (Link address do ELF)        ‚îÇ
‚îÇ     ASLR aplicado                      ‚îÇ                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

> [!IMPORTANT]
> O HHDM (Higher Half Direct Map) √© **obrigat√≥rio** para eliminar qualquer depend√™ncia de identity map na metade inferior. Isso permite que cada processo tenha userspace completamente isolado.

---

## üß© Componentes Principais

### 1. Higher Half Direct Map (HHDM)

**Arquivo:** `forge/src/mm/hhdm.rs`

O HHDM mapeia toda a RAM f√≠sica em uma regi√£o fixa do kernel space.

```rust
/// Base do Higher Half Direct Map
pub const HHDM_BASE: u64 = 0xFFFF_8000_0000_0000;

/// Converte endere√ßo f√≠sico para virtual (HHDM)
#[inline(always)]
pub fn phys_to_virt<T>(phys: u64) -> *mut T {
    (HHDM_BASE + phys) as *mut T
}

/// Converte endere√ßo virtual (HHDM) para f√≠sico
#[inline(always)]
pub fn virt_to_phys(virt: u64) -> u64 {
    debug_assert!(virt >= HHDM_BASE);
    virt - HHDM_BASE
}
```

**Implementa√ß√£o no Boot:**
- Bootloader (Ignite) mapeia toda RAM detectada em `HHDM_BASE + phys`
- Usa huge pages (2MB) para efici√™ncia
- Global bit setado para n√£o flush no context switch

---

### 2. Page Frame Manager (PFM)

**Arquivo:** `forge/src/mm/pfm/mod.rs`

Substitui o conceito de simples bitmap por um sistema de **ownership expl√≠cito**.

```rust
/// Estado de um frame f√≠sico
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum FrameState {
    /// Frame livre, dispon√≠vel para aloca√ß√£o
    Free,
    /// Frame usado por exatamente um processo
    Owned { owner: Pid },
    /// Frame compartilhado (COW ou shared memory)
    Shared { ref_count: u32 },
    /// Frame do kernel (n√£o pode ser liberado por userspace)
    Kernel,
    /// Frame pinned (n√£o swappable, n√£o movable)
    Pinned { owner: Pid },
    /// Frame usado por hardware (framebuffer, DMA)
    Device,
}

/// Metadados de um frame f√≠sico (Compacto: 32 bytes)
#[repr(C, align(32))]
pub struct FrameInfo {
    /// Estado e Flags compactados (Memory ordering: AcqRel/SeqCst)
    pub state_flags: AtomicU64,
    /// Contador de refer√™ncias (At√¥mico)
    pub ref_count: AtomicU32,
    /// Lock fino (TicketLock ou Mutex de 1-byte)
    pub lock: TicketLock,
    /// Reverse Mapping Escal√°vel:
    /// - Se 1-3 refs: Armazena inline (Small Array)
    /// - Se >3 refs: Ponteiro para Hashed bucket / Radix tree compressa
    pub rmap_data: RMapData,
    /// Metadados de NUMA e Zone
    pub numa_node: u16,
    /// Invalidation Counter (Fast-path para TLB shootdown)
    pub inv_count: AtomicU32,
}

/// Gerenciador de frames f√≠sicos
pub struct PageFrameManager {
    /// Array de metadados alocado no early-boot.
    /// Estrat√©gia: Paginado se RAM > 512GB para economizar mem√≥ria √∫til.
    frames: &'static mut [FrameInfo],
    /// Caches per-CPU (Lockless LIFO)
    cpu_caches: [CpuFrameCache; MAX_CPUS],
    stats: PfmStats,
}

impl PageFrameManager {
    /// Aloca frame com ownership expl√≠cito (tenta cache local primeiro)
    pub fn alloc_frame(&self, owner: Pid, flags: FrameFlags) -> Option<PhysAddr> { ... }
    
    /// Libera frame (decrementa refcount, limpa rmap se zero)
    pub fn free_frame(&self, frame: PhysAddr, owner: Pid) -> Result<(), PfmError> { ... }
    
    /// Reverse Map: Adiciona refer√™ncia de um PTE a este frame
    pub fn rmap_add(&self, frame: PhysAddr, pte_ptr: *mut PageTableEntry) { ... }

    /// Reverse Map: Remove todas as refer√™ncias (para eviction)
    pub fn rmap_unmap_all(&self, frame: PhysAddr) { ... }
}
```

> [!NOTE]
> O PFM √© constru√≠do **sobre** o PMM existente. O PMM continua gerenciando o bitmap de aloca√ß√£o, mas o PFM adiciona a camada de ownership e refcount.

---

### 3. Address Space Manager

**Arquivo:** `forge/src/mm/aspace/mod.rs`

Cada processo tem seu pr√≥prio `AddressSpace`, que gerencia a PML4 e a lista de VMAs.

```rust
/// Address Space de um processo
pub struct AddressSpace {
    /// Endere√ßo f√≠sico da PML4 (CR3)
    pml4: PhysAddr,
    /// Lista de VMAs ordenadas por endere√ßo
    vmas: RBTree<VirtAddr, VMA>,
    /// PID do processo dono
    owner: Pid,
    /// Estat√≠sticas
    stats: AddressSpaceStats,
    /// Lock para a √°rvore de VMAs (Read-Heavy)
    vma_lock: SpinRwLock<()>,
    /// Lock para as tabelas de p√°ginas (Escrita/Manuten√ß√£o)
    table_lock: SpinLock<()>,
    /// PCID (Process Context ID) atribu√≠do a este ASpace
    pcid: u16,
    /// Generation counter para TLB batching
    tlb_gen: AtomicU64,
}

impl AddressSpace {
    /// Cria novo address space VAZIO para userspace
    /// Kernel half √© sempre copiado, userspace √© completamente vazio
    pub fn new(owner: Pid) -> Result<Self, MmError> {
        let pml4 = PageFrameManager::alloc_frame(Pid::KERNEL, FrameFlags::KERNEL)?;
        unsafe {
            // Zerar toda a PML4
            memzero(phys_to_virt(pml4), PAGE_SIZE);
            // Copiar APENAS kernel half (entries 256-511)
            copy_kernel_mappings(pml4);
        }
        Ok(Self {
            pml4,
            vmas: RBTree::new(),
            owner,
            stats: AddressSpaceStats::default(),
            lock: SpinRwLock::new(()),
        })
    }
    
    /// Mapeia nova regi√£o (cria VMA)
    pub fn map_region(
        &mut self,
        hint: Option<VirtAddr>,
        size: usize,
        prot: Protection,
        flags: VmaFlags,
        intent: MemoryIntent,
    ) -> Result<VirtAddr, MmError> { ... }
    
    /// Remove mapeamento
    pub fn unmap_region(&mut self, addr: VirtAddr, size: usize) -> Result<(), MmError> { ... }
    
    /// Trata page fault
    pub fn handle_fault(
        &mut self, 
        addr: VirtAddr, 
        access: AccessType
    ) -> Result<PhysAddr, FaultResult> { ... }
}
```

---

### 4. Virtual Memory Area (VMA)

**Arquivo:** `forge/src/mm/aspace/vma.rs`

Cada regi√£o de mem√≥ria virtual √© descrita por uma VMA com **inten√ß√£o sem√¢ntica**.

```rust
/// Inten√ß√£o de uso da mem√≥ria
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum MemoryIntent {
    /// C√≥digo execut√°vel (ELF .text)
    Code,
    /// Dados inicializados (ELF .data)
    Data,
    /// Dados n√£o inicializados (ELF .bss)
    Bss,
    /// Heap do processo
    Heap,
    /// Stack do processo
    Stack,
    /// Arquivo mapeado (read-only shared)
    FileReadOnly,
    /// Arquivo mapeado (private COW)
    FilePrivate,
    /// Shared memory (IPC)
    SharedMemory,
    /// Framebuffer / DMA buffer
    DeviceBuffer,
    /// Guard page (n√£o mape√°vel, causa SIGSEGV)
    Guard,
}

/// Virtual Memory Area
pub struct VMA {
    /// Endere√ßo virtual inicial (page-aligned)
    pub start: VirtAddr,
    /// Endere√ßo virtual final (exclusive, page-aligned)  
    pub end: VirtAddr,
    /// Prote√ß√£o (Read/Write/Execute)
    pub protection: Protection,
    /// Flags de comportamento
    pub flags: VmaFlags,
    /// Inten√ß√£o sem√¢ntica
    pub intent: MemoryIntent,
    /// Backing (an√¥nimo, arquivo, ou VMO)
    pub backing: VmaBacking,
    /// Estat√≠sticas
    pub stats: VmaStats,
}

/// Backing de uma VMA
pub enum VmaBacking {
    /// Mem√≥ria an√¥nima (zero-fill on demand)
    Anonymous,
    /// Arquivo mapeado
    File { 
        vnode: Arc<VNode>,
        offset: u64,
    },
    /// VMO (Virtual Memory Object)
    Vmo { 
        vmo: Arc<VMO>,
        offset: usize,
    },
}

/// Flags de VMA
bitflags! {
    pub struct VmaFlags: u32 {
        /// Regi√£o pode crescer (heap)
        const GROWABLE = 1 << 0;
        /// Regi√£o cresce para baixo (stack)
        const GROWS_DOWN = 1 << 1;
        /// Copy-on-write
        const COW = 1 << 2;
        /// Shared entre processos
        const SHARED = 1 << 3;
        /// Locked in memory (n√£o swappable)
        const LOCKED = 1 << 4;
        /// Hint: streaming access
        const STREAMING = 1 << 5;
        /// Hint: descart√°vel se press√£o
        const DISCARDABLE = 1 << 6;
        /// Nunca fazer COW (sempre private)
        const NO_COW = 1 << 7;
    }
}
```

---

### 5. Page Fault Handler

**Arquivo:** `forge/src/mm/fault.rs`

O page fault √© o **mecanismo central** para aloca√ß√£o lazy e COW.

```rust
/// Resultado de um page fault
pub enum FaultResult {
    /// Fault resolvido, continuar execu√ß√£o
    Resolved(PhysAddr),
    /// Fault devido a COW, p√°gina copiada
    CowResolved(PhysAddr),
    /// Regi√£o n√£o mapeada, matar processo
    SegmentationFault,
    /// Viola√ß√£o de prote√ß√£o, matar processo
    ProtectionViolation,
    /// Stack overflow, tentar expandir ou matar
    StackOverflow,
    /// OOM, matar processo ou aguardar
    OutOfMemory,
}

/// Handler principal de page fault
pub fn handle_page_fault(
    addr: VirtAddr,
    error_code: PageFaultError,
    task: &mut Task,
) -> FaultResult {
    let aspace = &mut task.address_space;
    
    // 1. Encontrar VMA que cont√©m o endere√ßo
    let vma = match aspace.find_vma(addr) {
        Some(v) => v,
        None => {
            // Verificar se √© stack que pode crescer
            if aspace.can_expand_stack(addr) {
                aspace.expand_stack(addr)?;
                return handle_page_fault(addr, error_code, task);
            }
            return FaultResult::SegmentationFault;
        }
    };
    
    // 2. Verificar prote√ß√£o
    if !vma.protection.permits(error_code.access_type) {
        return FaultResult::ProtectionViolation;
    }
    
    // 3. Resolver baseado no estado da p√°gina
    match vma.get_page_state(addr) {
        PageState::NotPresent => {
            // Aloca√ß√£o lazy
            let frame = allocate_and_map(aspace, vma, addr)?;
            FaultResult::Resolved(frame)
        }
        PageState::CopyOnWrite if error_code.is_write => {
            // COW: copiar p√°gina
            let new_frame = copy_on_write(aspace, vma, addr)?;
            FaultResult::CowResolved(new_frame)
        }
        _ => FaultResult::ProtectionViolation,
    }
}
```

---

### 6. Syscalls de Mem√≥ria

**Arquivo:** [forge/src/syscall/memory/mod.rs](file:///D:/Github/RedstoneOS/forge/src/syscall/memory/mod.rs)

API userspace para gerenciar mem√≥ria.

```rust
// ============================================================================
// MMAP - Mapear regi√£o de mem√≥ria
// ============================================================================

/// sys_mmap(addr, size, prot, flags, fd, offset) -> Result<VirtAddr>
pub fn sys_mmap(
    hint: usize,
    size: usize,
    prot: u32,
    flags: u32,
    fd: i32,
    offset: u64,
) -> SysResult<usize> {
    let task = current_task();
    let mut aspace = task.address_space.lock();
    
    let protection = Protection::from_bits(prot)?;
    let vma_flags = VmaFlags::from_syscall(flags)?;
    
    // Determinar backing
    let backing = if fd >= 0 {
        let file = task.get_file(fd)?;
        VmaBacking::File { vnode: file.vnode.clone(), offset }
    } else {
        VmaBacking::Anonymous
    };
    
    // Determinar intent baseado em flags
    let intent = infer_intent(protection, vma_flags, backing);
    
    let addr = aspace.map_region(
        if hint == 0 { None } else { Some(VirtAddr::new(hint as u64)) },
        size,
        protection,
        vma_flags,
        intent,
    )?;
    
    Ok(addr.as_u64() as usize)
}

// ============================================================================
// MPROTECT - Alterar prote√ß√£o
// ============================================================================

/// sys_mprotect(addr, size, prot) -> Result<()>
pub fn sys_mprotect(addr: usize, size: usize, prot: u32) -> SysResult<usize> { ... }

// ============================================================================
// MUNMAP - Remover mapeamento
// ============================================================================

/// sys_munmap(addr, size) -> Result<()>
pub fn sys_munmap(addr: usize, size: usize) -> SysResult<usize> { ... }

// ============================================================================
// MADVISE - Dicas de uso (Userspace-guided)
// ============================================================================

/// sys_madvise(addr, size, advice) -> Result<()>
pub fn sys_madvise(addr: usize, size: usize, advice: i32) -> SysResult<usize> { ... }

---

## üöÄ Melhorias Industrial-Grade (O que nos separa de um kernel "toy")

### 1. Reverse Mappings (RMAP)
Para cada frame f√≠sico, o kernel mant√©m uma lista de todos os PTEs que apontam para ele. 
- **Utilidade:** Quando precisamos liberar um frame (evict) ou troc√°-lo (swap), o kernel sabe exatamente quais processos atualizar, sem varrer todas as tabelas de p√°ginas.
- **Implementa√ß√£o:** Lista encadeada de `(ASpace*, VirtAddr)` no `FrameInfo`.

### 2. SMP & TLB Shootdown (Batching + PCID)
Em sistemas multicore, a invalida√ß√£o de TLB √© o maior gargalo de sincroniza√ß√£o.
- **Batching:** N√£o enviamos um IPI para cada p√°gina removida. Acumulamos as invalida√ß√µes no `AddressSpace` e enviamos um √∫nico IPI "flush range" ao final da opera√ß√£o (ex: `munmap` de 1GB).
- **PCID (Process Context Identifiers):** Usamos tags de hardware no TLB para evitar flush total no context switch e permitir invalida√ß√µes seletivas.
- **Fast-path:** Invalidation counter lockless para pular IPIs se o ASpace n√£o estiver ativo em outros cores.

### 3. Page Reclaim (LRU / CLOCK-Pro)
- **Aging:** Implementar CLOCK-Pro ou Two-list LRU (Active/Inactive) para distinguir p√°ginas "quentes" de "frias".
- **kswapd:** Thread dedicada que acorda quando a RAM atinge o "low watermark" e dorme no "high watermark".
- **OOM Killer:** Heur√≠stica baseada no custo de recrea√ß√£o da task vs benef√≠cio de RAM liberada.

### 4. Seguran√ßa & At√¥micos (Memory Barriers)
- **Memory Ordering:** Todas as transi√ß√µes de `FrameInfo` (Free -> Owned) devem usar `Release` ordering, e leituras no fault handler `Acquire` ordering para garantir visibilidade em SMP.
- **Zero-on-Alloc:** Garantir que o buffer seja zerado usando instru√ß√µes NT (non-temporal) se poss√≠vel para n√£o poluir o cache.

### 5. NUMA-Awareness
Em servidores modernos, a RAM n√£o √© uniforme.
- **Policy:** O alocador tenta entregar RAM fisicamente pr√≥xima ao core que a solicitou (Node Locality).

### 6. File-backed VMAs & Page Cache
As p√°ginas mapeadas de arquivos precisam estar em sincronia com o Page Cache do kernel.
- **Integra√ß√£o:** O `rmap` permite que o kernel encontre todos os processos que mapearam um arquivo para fazer o flush/writeback quando o Page Cache decide gravar no disco.
- **Mecanismo:** `VmaBacking::File` aponta para o objeto de cache do VNode.

### 7. IOMMU & DMA Integration
Drivers de hardware (GPU, NIC) precisam de mem√≥ria cont√≠gua e vis√≠vel via IOMMU.
- **Pinned Frames:** Frames de DMA s√£o marcados como `Pinned` no `FrameInfo` e ignorados pelo `kswapd`.
- **Coer√™ncia:** O `rmap` deve rastrear se um frame est√° mapeado em um IOMMU group para invalidar caches de hardware se a p√°gina for movida.

### 8. Huge Pages (2MB / 1GB)
- **Split/Merge:** O kernel deve ser capaz de dividir uma Huge Page em 4KB pages se um processo chamar `mprotect` em apenas uma parte dela.
- **Alignment:** O alocador PFM deve garantir alinhamento natural (2MB align) para Huge Pages sem fragmenta√ß√£o excessiva.

---

## üîí Hierarquia de Locks e Invariantes

Para evitar deadlocks (especialmente em rmap vs page fault), a seguinte ordem **estrita** deve ser seguida:

1. **AddressSpace Lock** (vma_lock)
2. **VMA Lock** (se aplic√°vel)
3. **AddressSpace Table Lock** (table_lock)
4. **FrameInfo Lock** (per-frame)

**Invariante:** Nunca tente adquirir um lock de `AddressSpace` segurando um lock de `FrameInfo` sem usar `try_lock`. Se o reclaim precisar travar um ASpace que j√° est√° travado, ele deve recuar (backoff).

---

---

## üìä Fases de Implementa√ß√£o

### Fase 1: Funda√ß√£o Industrial (HHDM + Early Allocator) 
**Estimativa: 4-6 dias**

| Item | Descri√ß√£o | Arquivos |
|------|-----------|----------|
| 1.1 | Atualizar Bootloader para criar HHDM | `ignite/` |
| 1.2 | Early Boot Allocator (alocar FrameInfo array compacto) | `forge/src/mm/early.rs` |
| 1.3 | Implementar HHDM (Direct Map) com 1GB pages | `forge/src/mm/hhdm.rs` |
| 1.4 | Suporte a Huge Pages (2MB/1GB) no PFM | `forge/src/mm/vmm/huge.rs` |
| 1.5 | SMP: IPI Batching Engine para TLB | `forge/src/arch/x86_64/smp/tlb.rs` |
| 1.6 | PCID Management (x86_64) | `forge/src/arch/x86_64/vmm/pcid.rs` |

**Checkpoint:** Kernel boota com HHDM, suporte a Huge Pages e infra de TLB batching pronta.

---

### Fase 2: PFM com RMap Escal√°vel
**Estimativa: 4-6 dias**

| Item | Descri√ß√£o | Arquivos |
|------|-----------|----------|
| 2.1 | `FrameInfo` (32 bytes) com Atomic State | `forge/src/mm/pfm/frame.rs` |
| 2.2 | RMap: Small Array + Hashed Overflow | `forge/src/mm/pfm/rmap.rs` |
| 2.3 | Caches Per-CPU Lockless | `forge/src/mm/pfm/cache.rs` |
| 2.4 | IOMMU API & Pinned coordination | `forge/src/mm/pfm/iommu.rs` |
| 2.5 | Zero-on-Alloc (Background thread opcional) | `forge/src/mm/pfm/zero.rs` |

**Checkpoint:** Aloca√ß√£o de frames escal√°vel e metadados preparados para IOMMU e DMA.

---

### Fase 3: Address Space & Lock Strategy
**Estimativa: 5-7 dias**

| Item | Descri√ß√£o | Arquivos |
|------|-----------|----------|
| 3.1 | Implementar hierarquia de locks (VMA vs Table) | `forge/src/mm/aspace/mod.rs` |
| 3.2 | RBTree balanceada para VMAs | `forge/src/mm/aspace/rbtree.rs` |
| 3.3 | Integra√ß√£o de TLB Shootdown no unmap | `forge/src/mm/vmm/tlb.rs` |
| 3.4 | SMAP/SMEP Enforcing | `forge/src/arch/x86_64/cpu.rs` |
| 3.5 | Criar estrutura `VMA` | `forge/src/mm/aspace/vma.rs` |
| 3.6 | Implementar `AddressSpace` | `forge/src/mm/aspace/mod.rs` |
| 3.7 | Integrar com Task | [forge/src/sched/task/entity.rs](file:///D:/Github/RedstoneOS/forge/src/sched/task/entity.rs) |
| 3.8 | Novo [spawn()](file:///D:/Github/RedstoneOS/forge/src/sched/exec/loader.rs#36-266) usando AddressSpace | [forge/src/sched/exec/loader.rs](file:///D:/Github/RedstoneOS/forge/src/sched/exec/loader.rs) |
| 3.9 | Testes: spawn processos isolados | - |

**Checkpoint:** Processos isolados com prote√ß√£o de kernel e sincroniza√ß√£o SMP.

---

### Fase 4: Page Fault Handler
**Estimativa: 3-4 dias**

| Item | Descri√ß√£o | Arquivos |
|------|-----------|----------|
| 4.1 | Refatorar handler de #PF | [forge/src/arch/x86_64/interrupts.rs](file:///D:/Github/RedstoneOS/forge/src/arch/x86_64/interrupts.rs) |
| 4.2 | Implementar lazy allocation | `forge/src/mm/fault.rs` |
| 4.3 | Implementar COW | `forge/src/mm/fault.rs` |
| 4.4 | Stack expansion | `forge/src/mm/fault.rs` |
| 4.5 | Testes: lazy alloc, COW | - |

**Checkpoint:** P√°ginas alocadas sob demanda, COW funcional.

---

### Fase 5: Syscalls de Mem√≥ria
**Estimativa: 2-3 dias**

| Item | Descri√ß√£o | Arquivos |
|------|-----------|----------|
| 5.1 | Implementar `sys_mmap` | `forge/src/syscall/memory/mmap.rs` |
| 5.2 | Implementar `sys_munmap` | `forge/src/syscall/memory/mmap.rs` |
| 5.3 | Implementar [sys_mprotect](file:///D:/Github/RedstoneOS/forge/src/syscall/memory/alloc.rs#163-169) | `forge/src/syscall/memory/mmap.rs` |
| 5.4 | Implementar `sys_madvise` | `forge/src/syscall/memory/madvise.rs` |
| 5.5 | Atualizar SDK (redpowder) | `redpowder/src/mem/` |
| 5.6 | Testes: mmap/munmap userspace | - |

**Checkpoint:** Userspace pode alocar mem√≥ria via mmap.

---

### Fase 6: Heap Userspace (brk)
**Estimativa: 1-2 dias**

| Item | Descri√ß√£o | Arquivos |
|------|-----------|----------|
| 6.1 | Implementar `sys_brk` | `forge/src/syscall/memory/brk.rs` |
| 6.2 | VMA de heap por processo | `forge/src/mm/aspace/heap.rs` |
| 6.3 | Atualizar SDK allocator | `redpowder/src/mem/heap.rs` |
| 6.4 | Testes: Vec/String em userspace | - |

**Checkpoint:** Heap userspace funciona corretamente isolado.

---

### Fase 7: Shared Memory
**Estimativa: 2-3 dias**

| Item | Descri√ß√£o | Arquivos |
|------|-----------|----------|
| 7.1 | Criar VMO (Virtual Memory Object) | J√° existe: `forge/src/mm/types/vmo.rs` |
| 7.2 | Syscalls de VMO | `forge/src/syscall/memory/vmo.rs` |
| 7.3 | Mapeamento compartilhado | `forge/src/mm/aspace/shared.rs` |
| 7.4 | Testes: IPC via shared memory | - |

**Checkpoint:** Processos podem compartilhar mem√≥ria explicitamente.

---
### Fase 8: Reclaim & OOM Policy
**Estimativa: 4-6 dias**

| Item | Descri√ß√£o | Arquivos |
|------|-----------|----------|
| 8.1 | Page Aging (CLOCK-Pro ou 2-List LRU) | `forge/src/mm/reclaim/aging.rs` |
| 8.2 | Eviction Engine (rmap-based unmap) | `forge/src/mm/reclaim/evict.rs` |
| 8.3 | Thread `kswapd`: Pressure handling | `forge/src/mm/reclaim/kswapd.rs` |
| 8.4 | OOM Killer (Heur√≠stica: CPU time vs RAM) | `forge/src/mm/reclaim/oom.rs` |
| 8.5 | Swap: Backing store implementation | `forge/src/mm/swap/mod.rs` |

**Checkpoint:** Sistema resiste a press√£o de mem√≥ria com swap e eviction funcional.

---

### Fase 9: Observabilidade & Estresse
**Estimativa: 3-4 dias**

| Item | Descri√ß√£o | Arquivos |
|------|-----------|----------|
| 9.1 | Tracepoints para Alloc/Fault/Reclaim | `forge/src/mm/trace.rs` |
| 9.2 | KASAN & Fault Injection | `forge/src/mm/debug/` |
| 9.3 | Counters (Shared memory pages, dirty pages) | `forge/src/mm/stats.rs` |
| 9.4 | MMStress e Valida√ß√£o de carga real | `apps/mmstress/` |

---

## üìÅ Estrutura de Arquivos Proposta

```
forge/src/mm/
‚îú‚îÄ‚îÄ mod.rs                    # Re-exports e init()
‚îú‚îÄ‚îÄ config.rs                 # Constantes (atualizar)
‚îú‚îÄ‚îÄ error.rs                  # Tipos de erro (atualizar)
‚îÇ
‚îú‚îÄ‚îÄ hhdm.rs                   # [NOVO] Higher Half Direct Map
‚îÇ
‚îú‚îÄ‚îÄ pfm/                      # [NOVO] Page Frame Manager
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs                # API principal
‚îÇ   ‚îú‚îÄ‚îÄ frame.rs              # FrameInfo, FrameState
‚îÇ   ‚îú‚îÄ‚îÄ alloc.rs              # Aloca√ß√£o com ownership
‚îÇ   ‚îî‚îÄ‚îÄ refcount.rs           # Gerenciamento de refcount
‚îÇ
‚îú‚îÄ‚îÄ aspace/                   # [NOVO] Address Space
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs                # AddressSpace
‚îÇ   ‚îú‚îÄ‚îÄ vma.rs                # VMA, MemoryIntent
‚îÇ   ‚îú‚îÄ‚îÄ rbtree.rs             # RBTree para VMAs
‚îÇ   ‚îú‚îÄ‚îÄ heap.rs               # Heap region management
‚îÇ   ‚îî‚îÄ‚îÄ shared.rs             # Shared memory
‚îÇ
‚îú‚îÄ‚îÄ fault.rs                  # [NOVO] Page fault handler
‚îÇ
‚îú‚îÄ‚îÄ pmm/                      # Physical Memory Manager (manter)
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îú‚îÄ‚îÄ bitmap.rs             # Manter como base
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ vmm/                      # Virtual Memory Manager (refatorar)
‚îÇ   ‚îú‚îÄ‚îÄ mod.rs
‚îÇ   ‚îú‚îÄ‚îÄ mapper.rs             # Atualizar create_new_p4
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ heap/                     # Kernel Heap (manter)
‚îÇ   ‚îî‚îÄ‚îÄ mod.rs
‚îÇ
‚îú‚îÄ‚îÄ types/                    # Tipos (manter/expandir)
‚îÇ   ‚îú‚îÄ‚îÄ vmo.rs                # VMO (j√° existe)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îî‚îÄ‚îÄ alloc/                    # Allocators (manter)
    ‚îú‚îÄ‚îÄ buddy.rs
    ‚îú‚îÄ‚îÄ slab.rs
    ‚îî‚îÄ‚îÄ ...
```

---

## ‚ö†Ô∏è Riscos e Mitiga√ß√µes

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| Bootloader n√£o suporta HHDM | M√©dia | Alta | Modificar Ignite antes de come√ßar |
| Deadlocks em rmap/locking circular | Alta | Cr√≠tica | Hierarquia estrita de locks (PFM -> ASpace -> VMA) |
| TLB Stale Mappings (SMP) | M√©dia | Cr√≠tica | IPIs s√≠ncronas para shootdown e barreiras de mem√≥ria |
| Overhead de metadados (FrameInfo) | Baixa | M√©dia | Aloca√ß√£o no early boot e uso de campos compactos |
| Corrup√ß√£o por DMA/IOMMU | M√©dia | Alta | Manter frames de hardware Pinned e usar IOMMU API |

---

## ‚úÖ Crit√©rios de Sucesso

1. **Boot completo** com HHDM e userspace vazio
2. **Supervisor + Firefly + Shell** funcionando sem corrup√ß√£o
3. **Page fault** resolvendo aloca√ß√µes lazy corretamente
4. **COW** funcionando para fork() (quando implementado)
5. **Zero compartilhamento acidental** entre processos
6. **Performance** similar ou melhor que implementa√ß√£o atual
7. **C√≥digo limpo** sem gambiarras ou "TODO: fix later"

---

## üìö Refer√™ncias T√©cnicas

- [Intel SDM Volume 3, Chapter 4 - Paging](https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html)
- [Linux mm/ subsystem](https://github.com/torvalds/linux/tree/master/mm)
- [Fuchsia Zircon VMO](https://fuchsia.dev/fuchsia-src/reference/kernel_objects/vm_object)
- [seL4 Memory Management](https://docs.sel4.systems/projects/sel4/api-doc.html)

---

## üéØ Pr√≥ximos Passos

1. **Revisar** este plano e aprovar arquitetura
2. **Modificar Ignite** (bootloader) para criar HHDM
3. **Implementar Fase 1** (HHDM no kernel)
4. **Testar** boot b√°sico
5. **Continuar** com fases subsequentes

> [!CAUTION]
> Este √© um refactoring **significativo** do subsistema mais cr√≠tico do kernel. Cada fase deve ser testada exaustivamente antes de prosseguir. N√£o h√° atalhos.
